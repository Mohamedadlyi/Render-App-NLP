{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bdUnqJONWjh",
        "outputId": "db140544-e7d4-4be5-f5c9-ac398681e403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                    id                                               text\n",
            "0  1009754958479151232  @toha_Altomy @gy_yah Ù‚Ù„ÙŠÙ„ÙŠÙ† Ø§Ø¯Ø¨ ÙˆÙ…Ù†Ø§ÙÙ‚ÙŠÙ†. Ù„Ùˆ Ø§...\n",
            "1  1009794751548313600  @AlmFaisal ğŸ˜‚ğŸ˜‚ Ø§Ù„Ù„ÙŠØ¨ÙŠÙŠÙ† Ù…ØªÙ‚Ù„Ø¨ÙŠÙ†!!!\\nØ¨Ø³ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© ...\n",
            "2  1019989115490787200  @smsm071990 @ALMOGRBE ÙƒÙ„ 20 ØªØ§Ù†ÙŠÙ‡ Ø´Ø§Ø¨ Ù„ÙŠØ¨ÙŠ Ø¨ÙŠØ±...\n",
            "3  1035479791758135168  @AboryPro @lyranoo85 Ø±Ø§Ù†ÙŠØ§ Ø¹Ù‚Ù„ÙŠØªÙƒ Ù…ØªØ®Ù„ÙØ©. Ø§ÙˆÙ„Ø§...\n",
            "4  1035481122921164800  @lyranoo85 Ø´ÙƒÙ„Ùƒ Ù…ØªØ¹Ù‚Ø¯Ø© Ø¹Ù„Ø´Ø§Ù† Ø§Ù„Ø±Ø§Ø¬Ù„ Ù„ÙŠ ØªØ­Ø¨ÙŠÙ‡ Ø§...\n",
            "                    id dialect\n",
            "0  1009754958479151232      LY\n",
            "1  1009794751548313600      LY\n",
            "2  1019989115490787200      LY\n",
            "3  1035479791758135168      LY\n",
            "4  1035481122921164800      LY\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "dbfile = 'dialects_database.db'\n",
        "\n",
        "conn = sqlite3.connect(dbfile)\n",
        "\n",
        "Data_df = pd.read_sql(f\"SELECT * FROM id_text\", conn)\n",
        "\n",
        "type_df = pd.read_sql(f\"SELECT * FROM id_dialect\", conn)\n",
        "\n",
        "conn.close()\n",
        "\n",
        "print(Data_df.head())\n",
        "print(type_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ__t79iNWjj",
        "outputId": "87c794b3-c117-4965-d447-71130e41359b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(118180,)\n",
            "(29545,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Data_df['text'], type_df['dialect'], test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Lv2CnfeNWjj",
        "outputId": "71048f03-ccf9-4809-c24b-7587d6a9931f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['EG', 'LY', 'LB', 'SD', 'MA'], dtype=object)"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmu1EjM0NWjj",
        "outputId": "c25cb898-146c-41cf-8d63-0c61f31c82c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wajKsCRMNWjj",
        "outputId": "9ac6b881-0c29-4605-ed03-c4a0b2989f61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8wIfkVTNWjk",
        "outputId": "75c0377b-57a6-46d6-daed-88ca76d7214a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z46p1EbRNWjk",
        "outputId": "69303132-4e51-4fc9-b309-7b9f97b1761c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57485     Ø§Ù„Ø¯ÙÙ†ÙŠØ§ Ø¯ÙŠ ÙÙŠÙ‡Ø§ Ø§Ù„Ø­Ù„Ùˆ ÙˆØ§Ù„ÙˆØ­Ø´* https://t.co/2o4...\n",
              "61118     @shimaagamal Ø§Ù†Ø§ Ø¨Ù‚ÙŠØª Ø¨  Ø§Ø¹Ù…Ù„ ÙƒØ¯Ù‡ Ø¹Ù„Ù‰ ÙÙƒØ±Ø© ğŸ˜ ....\n",
              "48452     Ø§Ù„Ø¨ÙˆØ³Øª Ø¨ØªØ§Ø¹ Ø®Ø§ÙÙŠÙŠØ± Ø³ÙˆÙ„Ø§Ù†Ø§ Ø·Ù„Ø¹ Ø§Ù†Ù‡ ÙÙŠÙ‡ Ù‡Ø§ÙƒØ± ØªØ±Ùƒ...\n",
              "95030     Ø§Ø­Ù„ÙŠ birth day gift Ø¯ÙŠ ÙˆÙ„Ø§ Ø§ÙŠÙ‡ ğŸ˜‚\\n#Ø§ÙØ±ÙŠÙ‚ÙŠØ§_ÙŠØ§_...\n",
              "96136                @maganenoo Ø­Ø¨ÙŠØ¨Ù‰ Ù‚Ø¯Ù‡Ø§ ÙŠØ§ ÙƒØ¨ÙŠØ± ÙˆØ§Ù„Ù„Ù‡ â¤ğŸ˜‚\n",
              "1966      @kosai1khauli Ø¨ÙŠØ¬Ù†Ù†Ù†Ù† ÙˆØ­Ø¨ÙŠØª ÙƒØªÙŠØ± ÙƒØªÙŠØ±  Ø§Ù„Ø¨Ø±Ù…ÙˆÙˆ...\n",
              "73177     ÙÙŠÙ‡ Ø³Ù…ÙƒÙ‡ Ø¥Ø³Ù…Ù‡Ø§ Ø±Ø¹ÙŠØ¯Ù‡\\nØ¨ØªØ±Ø¹Ø¯-Ø¨ØªÙƒÙ‡Ø±Ø¨ ÙŠØ¹Ù†ÙŠ\\nØ­Ø¬Ù…Ù‡Ø§...\n",
              "73035     Ø¨Ø§Ù„Ù†Ø³Ø¨Ù‡ Ù„Ù„Ù†Ø¬ÙˆÙ… Ø§Ù„Ù„ÙŠ Ø¨ÙŠØ¯Ø§ÙØ¹Ùˆ Ø¹Ù† Ø§Ù„Ù…Ù‚Ø´ÙÙ‡\\n ÙˆØ¨ÙŠÙ‚Ùˆ...\n",
              "92410     Ø§Ù„Ù„Ù‰ Ù‡ÙŠØªØ§Ø¨Ø¹Ù†Ù‰ Ù‡ØªØ§Ø¨Ø¹Ù‡\\n#ÙƒÙ„Ø§Ù…_Ù…Ø¹Ù„Ù…ÙŠÙ†_Ø§Ù„Ø®Ù…ÙŠØ³\\n#Ø§Ù„...\n",
              "121942    @weneldawle Ù…Ø´Ù„ÙÙ‡ Ù‡ÙŠØ¯ÙŠ ğŸ˜‚ğŸ˜‚ğŸ˜‚\\nØ§Ø°Ø§ ØµØ¨ÙŠÙ‡ ØªØ³ØªØ¹Ù…Ù„ Ù‡ÙŠ...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j12w0M8VNWjk",
        "outputId": "7f025a21-3a4c-4d5d-c5b3-c4344ab38d58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57485              Ø§Ù„Ø¯ÙÙ†ÙŠØ§ Ø¯ÙŠ ÙÙŠÙ‡Ø§ Ø§Ù„Ø­Ù„Ùˆ ÙˆØ§Ù„ÙˆØ­Ø´* ://./24430\n",
              "61118     @ Ø§Ù†Ø§ Ø¨Ù‚ÙŠØª Ø¨  Ø§Ø¹Ù…Ù„ ÙƒØ¯Ù‡ Ø¹Ù„Ù‰ ÙÙƒØ±Ø© ğŸ˜ ... Ùˆ Ù„ÙŠÙ‡ Ø§Ùˆ...\n",
              "48452     Ø§Ù„Ø¨ÙˆØ³Øª Ø¨ØªØ§Ø¹ Ø®Ø§ÙÙŠÙŠØ± Ø³ÙˆÙ„Ø§Ù†Ø§ Ø·Ù„Ø¹ Ø§Ù†Ù‡ ÙÙŠÙ‡ Ù‡Ø§ÙƒØ± ØªØ±Ùƒ...\n",
              "95030                Ø§Ø­Ù„ÙŠ    Ø¯ÙŠ ÙˆÙ„Ø§ Ø§ÙŠÙ‡ ğŸ˜‚\\n#Ø§ÙØ±ÙŠÙ‚ÙŠØ§_ÙŠØ§_ÙˆØ¯Ø§Ø¯\n",
              "96136                         @ Ø­Ø¨ÙŠØ¨Ù‰ Ù‚Ø¯Ù‡Ø§ ÙŠØ§ ÙƒØ¨ÙŠØ± ÙˆØ§Ù„Ù„Ù‡ â¤ğŸ˜‚\n",
              "1966      @1 Ø¨ÙŠØ¬Ù†Ù†Ù†Ù† ÙˆØ­Ø¨ÙŠØª ÙƒØªÙŠØ± ÙƒØªÙŠØ±  Ø§Ù„Ø¨Ø±Ù…ÙˆÙˆÙˆ Ø§Ù„Ù Ù…Ø¨Ø±ÙˆÙˆ...\n",
              "73177     ÙÙŠÙ‡ Ø³Ù…ÙƒÙ‡ Ø¥Ø³Ù…Ù‡Ø§ Ø±Ø¹ÙŠØ¯Ù‡\\nØ¨ØªØ±Ø¹Ø¯-Ø¨ØªÙƒÙ‡Ø±Ø¨ ÙŠØ¹Ù†ÙŠ\\nØ­Ø¬Ù…Ù‡Ø§...\n",
              "73035     Ø¨Ø§Ù„Ù†Ø³Ø¨Ù‡ Ù„Ù„Ù†Ø¬ÙˆÙ… Ø§Ù„Ù„ÙŠ Ø¨ÙŠØ¯Ø§ÙØ¹Ùˆ Ø¹Ù† Ø§Ù„Ù…Ù‚Ø´ÙÙ‡\\n ÙˆØ¨ÙŠÙ‚Ùˆ...\n",
              "92410     Ø§Ù„Ù„Ù‰ Ù‡ÙŠØªØ§Ø¨Ø¹Ù†Ù‰ Ù‡ØªØ§Ø¨Ø¹Ù‡\\n#ÙƒÙ„Ø§Ù…_Ù…Ø¹Ù„Ù…ÙŠÙ†_Ø§Ù„Ø®Ù…ÙŠØ³\\n#Ø§Ù„...\n",
              "121942    @ Ù…Ø´Ù„ÙÙ‡ Ù‡ÙŠØ¯ÙŠ ğŸ˜‚ğŸ˜‚ğŸ˜‚\\nØ§Ø°Ø§ ØµØ¨ÙŠÙ‡ ØªØ³ØªØ¹Ù…Ù„ Ù‡ÙŠÙƒ Ù…Ù†Ø·Ù‚ ÙˆÙ‡ÙŠ...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def remove_english_characters(text):\n",
        "    pattern = r'[a-zA-Z]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "X_train = X_train.apply(remove_english_characters)\n",
        "\n",
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-OFPm3hNWjk",
        "outputId": "e621a038-b5d8-47de-ea78-492b5495a01a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57485                   Ø§Ù„Ø¯ÙÙ†ÙŠØ§ Ø¯ÙŠ ÙÙŠÙ‡Ø§ Ø§Ù„Ø­Ù„Ùˆ ÙˆØ§Ù„ÙˆØ­Ø´* ://./\n",
              "61118     @ Ø§Ù†Ø§ Ø¨Ù‚ÙŠØª Ø¨  Ø§Ø¹Ù…Ù„ ÙƒØ¯Ù‡ Ø¹Ù„Ù‰ ÙÙƒØ±Ø© ğŸ˜ ... Ùˆ Ù„ÙŠÙ‡ Ø§Ùˆ...\n",
              "48452     Ø§Ù„Ø¨ÙˆØ³Øª Ø¨ØªØ§Ø¹ Ø®Ø§ÙÙŠÙŠØ± Ø³ÙˆÙ„Ø§Ù†Ø§ Ø·Ù„Ø¹ Ø§Ù†Ù‡ ÙÙŠÙ‡ Ù‡Ø§ÙƒØ± ØªØ±Ùƒ...\n",
              "95030                Ø§Ø­Ù„ÙŠ    Ø¯ÙŠ ÙˆÙ„Ø§ Ø§ÙŠÙ‡ ğŸ˜‚\\n#Ø§ÙØ±ÙŠÙ‚ÙŠØ§_ÙŠØ§_ÙˆØ¯Ø§Ø¯\n",
              "96136                         @ Ø­Ø¨ÙŠØ¨Ù‰ Ù‚Ø¯Ù‡Ø§ ÙŠØ§ ÙƒØ¨ÙŠØ± ÙˆØ§Ù„Ù„Ù‡ â¤ğŸ˜‚\n",
              "1966      @ Ø¨ÙŠØ¬Ù†Ù†Ù†Ù† ÙˆØ­Ø¨ÙŠØª ÙƒØªÙŠØ± ÙƒØªÙŠØ±  Ø§Ù„Ø¨Ø±Ù…ÙˆÙˆÙˆ Ø§Ù„Ù Ù…Ø¨Ø±ÙˆÙˆÙƒ...\n",
              "73177     ÙÙŠÙ‡ Ø³Ù…ÙƒÙ‡ Ø¥Ø³Ù…Ù‡Ø§ Ø±Ø¹ÙŠØ¯Ù‡\\nØ¨ØªØ±Ø¹Ø¯-Ø¨ØªÙƒÙ‡Ø±Ø¨ ÙŠØ¹Ù†ÙŠ\\nØ­Ø¬Ù…Ù‡Ø§...\n",
              "73035     Ø¨Ø§Ù„Ù†Ø³Ø¨Ù‡ Ù„Ù„Ù†Ø¬ÙˆÙ… Ø§Ù„Ù„ÙŠ Ø¨ÙŠØ¯Ø§ÙØ¹Ùˆ Ø¹Ù† Ø§Ù„Ù…Ù‚Ø´ÙÙ‡\\n ÙˆØ¨ÙŠÙ‚Ùˆ...\n",
              "92410     Ø§Ù„Ù„Ù‰ Ù‡ÙŠØªØ§Ø¨Ø¹Ù†Ù‰ Ù‡ØªØ§Ø¨Ø¹Ù‡\\n#ÙƒÙ„Ø§Ù…_Ù…Ø¹Ù„Ù…ÙŠÙ†_Ø§Ù„Ø®Ù…ÙŠØ³\\n#Ø§Ù„...\n",
              "121942    @ Ù…Ø´Ù„ÙÙ‡ Ù‡ÙŠØ¯ÙŠ ğŸ˜‚ğŸ˜‚ğŸ˜‚\\nØ§Ø°Ø§ ØµØ¨ÙŠÙ‡ ØªØ³ØªØ¹Ù…Ù„ Ù‡ÙŠÙƒ Ù…Ù†Ø·Ù‚ ÙˆÙ‡ÙŠ...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def remove_numbers(text):\n",
        "    pattern = r'[\\d+]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "X_train = X_train.apply(remove_numbers)\n",
        "\n",
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzc-EMRENWjk",
        "outputId": "2fdc6958-2f56-42eb-aa8e-437a43c4f4e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57485                          Ø§Ù„Ø¯Ù†ÙŠØ§ Ø¯ÙŠ ÙÙŠÙ‡Ø§ Ø§Ù„Ø­Ù„Ùˆ ÙˆØ§Ù„ÙˆØ­Ø´ \n",
              "61118      Ø§Ù†Ø§ Ø¨Ù‚ÙŠØª Ø¨  Ø§Ø¹Ù…Ù„ ÙƒØ¯Ù‡ Ø¹Ù„Ù‰ ÙÙƒØ±Ø©   Ùˆ Ù„ÙŠÙ‡ Ø§ÙˆØ¬Ø¹ Ø§ÙŠ...\n",
              "48452     Ø§Ù„Ø¨ÙˆØ³Øª Ø¨ØªØ§Ø¹ Ø®Ø§ÙÙŠÙŠØ± Ø³ÙˆÙ„Ø§Ù†Ø§ Ø·Ù„Ø¹ Ø§Ù†Ù‡ ÙÙŠÙ‡ Ù‡Ø§ÙƒØ± ØªØ±Ùƒ...\n",
              "95030                  Ø§Ø­Ù„ÙŠ    Ø¯ÙŠ ÙˆÙ„Ø§ Ø§ÙŠÙ‡ \\nØ§ÙØ±ÙŠÙ‚ÙŠØ§_ÙŠØ§_ÙˆØ¯Ø§Ø¯\n",
              "96136                             Ø­Ø¨ÙŠØ¨Ù‰ Ù‚Ø¯Ù‡Ø§ ÙŠØ§ ÙƒØ¨ÙŠØ± ÙˆØ§Ù„Ù„Ù‡ \n",
              "1966       Ø¨ÙŠØ¬Ù†Ù†Ù†Ù† ÙˆØ­Ø¨ÙŠØª ÙƒØªÙŠØ± ÙƒØªÙŠØ±  Ø§Ù„Ø¨Ø±Ù…ÙˆÙˆÙˆ Ø§Ù„Ù Ù…Ø¨Ø±ÙˆÙˆÙƒ ...\n",
              "73177     ÙÙŠÙ‡ Ø³Ù…ÙƒÙ‡ Ø¥Ø³Ù…Ù‡Ø§ Ø±Ø¹ÙŠØ¯Ù‡\\nØ¨ØªØ±Ø¹Ø¯Ø¨ØªÙƒÙ‡Ø±Ø¨ ÙŠØ¹Ù†ÙŠ\\nØ­Ø¬Ù…Ù‡Ø§ ...\n",
              "73035     Ø¨Ø§Ù„Ù†Ø³Ø¨Ù‡ Ù„Ù„Ù†Ø¬ÙˆÙ… Ø§Ù„Ù„ÙŠ Ø¨ÙŠØ¯Ø§ÙØ¹Ùˆ Ø¹Ù† Ø§Ù„Ù…Ù‚Ø´ÙÙ‡\\n ÙˆØ¨ÙŠÙ‚Ùˆ...\n",
              "92410     Ø§Ù„Ù„Ù‰ Ù‡ÙŠØªØ§Ø¨Ø¹Ù†Ù‰ Ù‡ØªØ§Ø¨Ø¹Ù‡\\nÙƒÙ„Ø§Ù…_Ù…Ø¹Ù„Ù…ÙŠÙ†_Ø§Ù„Ø®Ù…ÙŠØ³\\nØ§Ù„Ø§Ù…...\n",
              "121942     Ù…Ø´Ù„ÙÙ‡ Ù‡ÙŠØ¯ÙŠ \\nØ§Ø°Ø§ ØµØ¨ÙŠÙ‡ ØªØ³ØªØ¹Ù…Ù„ Ù‡ÙŠÙƒ Ù…Ù†Ø·Ù‚ ÙˆÙ‡ÙŠÙƒ Ø§Ù„...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def remove_special_characters(text):\n",
        "    pattern = r'[^\\w\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "X_train = X_train.apply(remove_special_characters)\n",
        "\n",
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ugBUngCNWjl",
        "outputId": "05a6a234-eb06-4e91-c89f-2bb317f6ae81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57485                          Ø§Ù„Ø¯Ù†ÙŠØ§ Ø¯ÙŠ ÙÙŠÙ‡Ø§ Ø§Ù„Ø­Ù„Ùˆ ÙˆØ§Ù„ÙˆØ­Ø´ \n",
              "61118      Ø§Ù†Ø§ Ø¨Ù‚ÙŠØª Ø¨  Ø§Ø¹Ù…Ù„ ÙƒØ¯Ù‡ Ø¹Ù„Ù‰ ÙÙƒØ±Ø©   Ùˆ Ù„ÙŠÙ‡ Ø§ÙˆØ¬Ø¹ Ø§ÙŠ...\n",
              "48452     Ø§Ù„Ø¨ÙˆØ³Øª Ø¨ØªØ§Ø¹ Ø®Ø§ÙÙŠÙŠØ± Ø³ÙˆÙ„Ø§Ù†Ø§ Ø·Ù„Ø¹ Ø§Ù†Ù‡ ÙÙŠÙ‡ Ù‡Ø§ÙƒØ± ØªØ±Ùƒ...\n",
              "95030                   Ø§Ø­Ù„ÙŠ    Ø¯ÙŠ ÙˆÙ„Ø§ Ø§ÙŠÙ‡  Ø§ÙØ±ÙŠÙ‚ÙŠØ§ ÙŠØ§ ÙˆØ¯Ø§Ø¯\n",
              "96136                             Ø­Ø¨ÙŠØ¨Ù‰ Ù‚Ø¯Ù‡Ø§ ÙŠØ§ ÙƒØ¨ÙŠØ± ÙˆØ§Ù„Ù„Ù‡ \n",
              "1966       Ø¨ÙŠØ¬Ù†Ù†Ù†Ù† ÙˆØ­Ø¨ÙŠØª ÙƒØªÙŠØ± ÙƒØªÙŠØ±  Ø§Ù„Ø¨Ø±Ù…ÙˆÙˆÙˆ Ø§Ù„Ù Ù…Ø¨Ø±ÙˆÙˆÙƒ ...\n",
              "73177     ÙÙŠÙ‡ Ø³Ù…ÙƒÙ‡ Ø¥Ø³Ù…Ù‡Ø§ Ø±Ø¹ÙŠØ¯Ù‡ Ø¨ØªØ±Ø¹Ø¯Ø¨ØªÙƒÙ‡Ø±Ø¨ ÙŠØ¹Ù†ÙŠ Ø­Ø¬Ù…Ù‡Ø§ ØµØº...\n",
              "73035     Ø¨Ø§Ù„Ù†Ø³Ø¨Ù‡ Ù„Ù„Ù†Ø¬ÙˆÙ… Ø§Ù„Ù„ÙŠ Ø¨ÙŠØ¯Ø§ÙØ¹Ùˆ Ø¹Ù† Ø§Ù„Ù…Ù‚Ø´ÙÙ‡  ÙˆØ¨ÙŠÙ‚ÙˆÙ„...\n",
              "92410     Ø§Ù„Ù„Ù‰ Ù‡ÙŠØªØ§Ø¨Ø¹Ù†Ù‰ Ù‡ØªØ§Ø¨Ø¹Ù‡ ÙƒÙ„Ø§Ù… Ù…Ø¹Ù„Ù…ÙŠÙ† Ø§Ù„Ø®Ù…ÙŠØ³ Ø§Ù„Ø§Ù…ÙŠØ±...\n",
              "121942     Ù…Ø´Ù„ÙÙ‡ Ù‡ÙŠØ¯ÙŠ  Ø§Ø°Ø§ ØµØ¨ÙŠÙ‡ ØªØ³ØªØ¹Ù…Ù„ Ù‡ÙŠÙƒ Ù…Ù†Ø·Ù‚ ÙˆÙ‡ÙŠÙƒ Ø§Ù„Ù...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def remove_underscores_and_enter(text):\n",
        "    pattern = r'[_\\n]'\n",
        "    text = re.sub(pattern, ' ', text)\n",
        "    return text\n",
        "\n",
        "X_train = X_train.apply(remove_underscores_and_enter)\n",
        "\n",
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cLxToGwNWjl",
        "outputId": "0085a00b-4a0c-4653-c23f-6b421e827e82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57485                           Ø§Ù„Ø¯Ù†ÙŠØ§ Ø¯ÙŠ ÙÙŠÙ‡Ø§ Ø§Ù„Ø­Ù„Ùˆ ÙˆØ§Ù„ÙˆØ­Ø´\n",
              "61118     Ø§Ù†Ø§ Ø¨Ù‚ÙŠØª Ø¨ Ø§Ø¹Ù…Ù„ ÙƒØ¯Ù‡ Ø¹Ù„Ù‰ ÙÙƒØ±Ø© Ùˆ Ù„ÙŠÙ‡ Ø§ÙˆØ¬Ø¹ Ø§ÙŠØ¯ÙŠ Øª...\n",
              "48452     Ø§Ù„Ø¨ÙˆØ³Øª Ø¨ØªØ§Ø¹ Ø®Ø§ÙÙŠÙŠØ± Ø³ÙˆÙ„Ø§Ù†Ø§ Ø·Ù„Ø¹ Ø§Ù†Ù‡ ÙÙŠÙ‡ Ù‡Ø§ÙƒØ± ØªØ±Ùƒ...\n",
              "95030                       Ø§Ø­Ù„ÙŠ Ø¯ÙŠ ÙˆÙ„Ø§ Ø§ÙŠÙ‡ Ø§ÙØ±ÙŠÙ‚ÙŠØ§ ÙŠØ§ ÙˆØ¯Ø§Ø¯\n",
              "96136                              Ø­Ø¨ÙŠØ¨Ù‰ Ù‚Ø¯Ù‡Ø§ ÙŠØ§ ÙƒØ¨ÙŠØ± ÙˆØ§Ù„Ù„Ù‡\n",
              "1966      Ø¨ÙŠØ¬Ù†Ù†Ù†Ù† ÙˆØ­Ø¨ÙŠØª ÙƒØªÙŠØ± ÙƒØªÙŠØ± Ø§Ù„Ø¨Ø±Ù…ÙˆÙˆÙˆ Ø§Ù„Ù Ù…Ø¨Ø±ÙˆÙˆÙƒ Ø­Ø¨...\n",
              "73177     ÙÙŠÙ‡ Ø³Ù…ÙƒÙ‡ Ø¥Ø³Ù…Ù‡Ø§ Ø±Ø¹ÙŠØ¯Ù‡ Ø¨ØªØ±Ø¹Ø¯Ø¨ØªÙƒÙ‡Ø±Ø¨ ÙŠØ¹Ù†ÙŠ Ø­Ø¬Ù…Ù‡Ø§ ØµØº...\n",
              "73035     Ø¨Ø§Ù„Ù†Ø³Ø¨Ù‡ Ù„Ù„Ù†Ø¬ÙˆÙ… Ø§Ù„Ù„ÙŠ Ø¨ÙŠØ¯Ø§ÙØ¹Ùˆ Ø¹Ù† Ø§Ù„Ù…Ù‚Ø´ÙÙ‡ ÙˆØ¨ÙŠÙ‚ÙˆÙ„Ùˆ...\n",
              "92410     Ø§Ù„Ù„Ù‰ Ù‡ÙŠØªØ§Ø¨Ø¹Ù†Ù‰ Ù‡ØªØ§Ø¨Ø¹Ù‡ ÙƒÙ„Ø§Ù… Ù…Ø¹Ù„Ù…ÙŠÙ† Ø§Ù„Ø®Ù…ÙŠØ³ Ø§Ù„Ø§Ù…ÙŠØ±...\n",
              "121942    Ù…Ø´Ù„ÙÙ‡ Ù‡ÙŠØ¯ÙŠ Ø§Ø°Ø§ ØµØ¨ÙŠÙ‡ ØªØ³ØªØ¹Ù…Ù„ Ù‡ÙŠÙƒ Ù…Ù†Ø·Ù‚ ÙˆÙ‡ÙŠÙƒ Ø§Ù„ÙØ§Ø¸...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def remove_extra_spaces(text):\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "X_train = X_train.apply(remove_extra_spaces)\n",
        "\n",
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goP44AZ4NWjl"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = remove_english_characters(text)\n",
        "    text = remove_numbers(text)\n",
        "    text = remove_special_characters(text)\n",
        "    text = remove_underscores_and_enter(text)\n",
        "    text = remove_extra_spaces(text)\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rn4-CZQCNWjl",
        "outputId": "023d4710-91fd-4dbe-f8e5-a2dd4e641412"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8295819935691319"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "X_test = X_test.apply(clean_text)\n",
        "\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgrpKRmhNWjl",
        "outputId": "12604510-5b50-4632-adec-f74580f219fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['EG'], dtype=object)"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_text = ' Ù„ÙŠÙ‡ Ø§ÙˆØ¬Ø¹ Ø§ÙŠØ¯ÙŠ'\n",
        "cleaned_text = clean_text(new_text)\n",
        "\n",
        "new_text_vectorized = vectorizer.transform([cleaned_text])\n",
        "\n",
        "model.predict(new_text_vectorized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmPbPz2GNWjm",
        "outputId": "7ddeb66f-1112-41af-b53b-60309b9be27f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8329666610255543"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "\n",
        "accuracy_score(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBqN-Cu0NWjm",
        "outputId": "aa046774-5f0a-4b60-9bec-30a59eee0fcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['EG'], dtype='<U2')"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_text = ' Ù„ÙŠÙ‡ Ø§ÙˆØ¬Ø¹ Ø§ÙŠØ¯ÙŠ'\n",
        "cleaned_text = clean_text(new_text)\n",
        "\n",
        "new_text_vectorized = vectorizer.transform([cleaned_text])\n",
        "\n",
        "model.predict(new_text_vectorized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qMJlLTONWjm",
        "outputId": "c257976a-bb11-4ca6-af24-9499afd1eda9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2955/2955 [==============================] - 818s 274ms/step - loss: 1.4565 - accuracy: 0.3913 - val_loss: 1.4524 - val_accuracy: 0.3869\n",
            "Epoch 2/10\n",
            "2955/2955 [==============================] - 806s 273ms/step - loss: 1.4539 - accuracy: 0.3914 - val_loss: 1.4531 - val_accuracy: 0.3869\n",
            "Epoch 3/10\n",
            "2955/2955 [==============================] - 835s 283ms/step - loss: 1.4533 - accuracy: 0.3914 - val_loss: 1.4521 - val_accuracy: 0.3869\n",
            "Epoch 4/10\n",
            "2955/2955 [==============================] - 836s 283ms/step - loss: 1.4532 - accuracy: 0.3914 - val_loss: 1.4522 - val_accuracy: 0.3869\n",
            "Epoch 5/10\n",
            "2955/2955 [==============================] - 820s 277ms/step - loss: 1.4531 - accuracy: 0.3914 - val_loss: 1.4523 - val_accuracy: 0.3869\n",
            "Epoch 6/10\n",
            "2955/2955 [==============================] - 809s 274ms/step - loss: 1.4530 - accuracy: 0.3914 - val_loss: 1.4523 - val_accuracy: 0.3869\n",
            "924/924 [==============================] - 58s 60ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#make a deep learning model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_sequences, padding='post', maxlen=100)\n",
        "\n",
        "X_test_padded = pad_sequences(X_test_sequences, padding='post', maxlen=100)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=100))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "model.fit(X_train_padded, y_train_categorical, validation_split=0.2, epochs=10, callbacks=[early_stopping])\n",
        "\n",
        "y_pred = model.predict(X_test_padded)\n",
        "\n",
        "y_pred = y_pred.argmax(axis=1)\n",
        "\n",
        "accuracy_score(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHotwhKkNWjm",
        "outputId": "923ff740-6b50-42c2-c0e1-e0cd8ae2ec2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "#save the model\n",
        "model.save('dialects_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gd40hIvNWjm",
        "outputId": "5181bbbb-f0b3-4bb4-d44a-6aedac05efd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 928 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002651D138A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array(['SD'], dtype=object)"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#try the model\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('dialects_model.h5')\n",
        "\n",
        "new_text = 'ÙŠØ¯'\n",
        "cleaned_text = clean_text(new_text)\n",
        "\n",
        "new_text_sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
        "\n",
        "new_text_padded = pad_sequences(new_text_sequence, padding='post', maxlen=100)\n",
        "\n",
        "model.predict(new_text_padded)\n",
        "\n",
        "label_encoder.inverse_transform([4])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu-fM1xSNWjm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
