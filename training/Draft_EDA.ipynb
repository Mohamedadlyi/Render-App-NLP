{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bdUnqJONWjh",
        "outputId": "db140544-e7d4-4be5-f5c9-ac398681e403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                    id                                               text\n",
            "0  1009754958479151232  @toha_Altomy @gy_yah قليلين ادب ومنافقين. لو ا...\n",
            "1  1009794751548313600  @AlmFaisal 😂😂 الليبيين متقلبين!!!\\nبس بالنسبة ...\n",
            "2  1019989115490787200  @smsm071990 @ALMOGRBE كل 20 تانيه شاب ليبي بير...\n",
            "3  1035479791758135168  @AboryPro @lyranoo85 رانيا عقليتك متخلفة. اولا...\n",
            "4  1035481122921164800  @lyranoo85 شكلك متعقدة علشان الراجل لي تحبيه ا...\n",
            "                    id dialect\n",
            "0  1009754958479151232      LY\n",
            "1  1009794751548313600      LY\n",
            "2  1019989115490787200      LY\n",
            "3  1035479791758135168      LY\n",
            "4  1035481122921164800      LY\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "dbfile = 'dialects_database.db'\n",
        "\n",
        "conn = sqlite3.connect(dbfile)\n",
        "\n",
        "Data_df = pd.read_sql(f\"SELECT * FROM id_text\", conn)\n",
        "\n",
        "type_df = pd.read_sql(f\"SELECT * FROM id_dialect\", conn)\n",
        "\n",
        "conn.close()\n",
        "\n",
        "print(Data_df.head())\n",
        "print(type_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ__t79iNWjj",
        "outputId": "87c794b3-c117-4965-d447-71130e41359b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(118180,)\n",
            "(29545,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Data_df['text'], type_df['dialect'], test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Lv2CnfeNWjj",
        "outputId": "71048f03-ccf9-4809-c24b-7587d6a9931f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['EG', 'LY', 'LB', 'SD', 'MA'], dtype=object)"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmu1EjM0NWjj",
        "outputId": "c25cb898-146c-41cf-8d63-0c61f31c82c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wajKsCRMNWjj",
        "outputId": "9ac6b881-0c29-4605-ed03-c4a0b2989f61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8wIfkVTNWjk",
        "outputId": "75c0377b-57a6-46d6-daed-88ca76d7214a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z46p1EbRNWjk",
        "outputId": "69303132-4e51-4fc9-b309-7b9f97b1761c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57485     الدُنيا دي فيها الحلو والوحش* https://t.co/2o4...\n",
              "61118     @shimaagamal انا بقيت ب  اعمل كده على فكرة 😁 ....\n",
              "48452     البوست بتاع خافيير سولانا طلع انه فيه هاكر ترك...\n",
              "95030     احلي birth day gift دي ولا ايه 😂\\n#افريقيا_يا_...\n",
              "96136                @maganenoo حبيبى قدها يا كبير والله ❤😂\n",
              "1966      @kosai1khauli بيجنننن وحبيت كتير كتير  البرموو...\n",
              "73177     فيه سمكه إسمها رعيده\\nبترعد-بتكهرب يعني\\nحجمها...\n",
              "73035     بالنسبه للنجوم اللي بيدافعو عن المقشفه\\n وبيقو...\n",
              "92410     اللى هيتابعنى هتابعه\\n#كلام_معلمين_الخميس\\n#ال...\n",
              "121942    @weneldawle مشلفه هيدي 😂😂😂\\nاذا صبيه تستعمل هي...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j12w0M8VNWjk",
        "outputId": "7f025a21-3a4c-4d5d-c5b3-c4344ab38d58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57485              الدُنيا دي فيها الحلو والوحش* ://./24430\n",
              "61118     @ انا بقيت ب  اعمل كده على فكرة 😁 ... و ليه او...\n",
              "48452     البوست بتاع خافيير سولانا طلع انه فيه هاكر ترك...\n",
              "95030                احلي    دي ولا ايه 😂\\n#افريقيا_يا_وداد\n",
              "96136                         @ حبيبى قدها يا كبير والله ❤😂\n",
              "1966      @1 بيجنننن وحبيت كتير كتير  البرمووو الف مبروو...\n",
              "73177     فيه سمكه إسمها رعيده\\nبترعد-بتكهرب يعني\\nحجمها...\n",
              "73035     بالنسبه للنجوم اللي بيدافعو عن المقشفه\\n وبيقو...\n",
              "92410     اللى هيتابعنى هتابعه\\n#كلام_معلمين_الخميس\\n#ال...\n",
              "121942    @ مشلفه هيدي 😂😂😂\\nاذا صبيه تستعمل هيك منطق وهي...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def remove_english_characters(text):\n",
        "    pattern = r'[a-zA-Z]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "X_train = X_train.apply(remove_english_characters)\n",
        "\n",
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-OFPm3hNWjk",
        "outputId": "e621a038-b5d8-47de-ea78-492b5495a01a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57485                   الدُنيا دي فيها الحلو والوحش* ://./\n",
              "61118     @ انا بقيت ب  اعمل كده على فكرة 😁 ... و ليه او...\n",
              "48452     البوست بتاع خافيير سولانا طلع انه فيه هاكر ترك...\n",
              "95030                احلي    دي ولا ايه 😂\\n#افريقيا_يا_وداد\n",
              "96136                         @ حبيبى قدها يا كبير والله ❤😂\n",
              "1966      @ بيجنننن وحبيت كتير كتير  البرمووو الف مبرووك...\n",
              "73177     فيه سمكه إسمها رعيده\\nبترعد-بتكهرب يعني\\nحجمها...\n",
              "73035     بالنسبه للنجوم اللي بيدافعو عن المقشفه\\n وبيقو...\n",
              "92410     اللى هيتابعنى هتابعه\\n#كلام_معلمين_الخميس\\n#ال...\n",
              "121942    @ مشلفه هيدي 😂😂😂\\nاذا صبيه تستعمل هيك منطق وهي...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def remove_numbers(text):\n",
        "    pattern = r'[\\d+]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "X_train = X_train.apply(remove_numbers)\n",
        "\n",
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzc-EMRENWjk",
        "outputId": "2fdc6958-2f56-42eb-aa8e-437a43c4f4e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57485                          الدنيا دي فيها الحلو والوحش \n",
              "61118      انا بقيت ب  اعمل كده على فكرة   و ليه اوجع اي...\n",
              "48452     البوست بتاع خافيير سولانا طلع انه فيه هاكر ترك...\n",
              "95030                  احلي    دي ولا ايه \\nافريقيا_يا_وداد\n",
              "96136                             حبيبى قدها يا كبير والله \n",
              "1966       بيجنننن وحبيت كتير كتير  البرمووو الف مبرووك ...\n",
              "73177     فيه سمكه إسمها رعيده\\nبترعدبتكهرب يعني\\nحجمها ...\n",
              "73035     بالنسبه للنجوم اللي بيدافعو عن المقشفه\\n وبيقو...\n",
              "92410     اللى هيتابعنى هتابعه\\nكلام_معلمين_الخميس\\nالام...\n",
              "121942     مشلفه هيدي \\nاذا صبيه تستعمل هيك منطق وهيك ال...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def remove_special_characters(text):\n",
        "    pattern = r'[^\\w\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "X_train = X_train.apply(remove_special_characters)\n",
        "\n",
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ugBUngCNWjl",
        "outputId": "05a6a234-eb06-4e91-c89f-2bb317f6ae81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57485                          الدنيا دي فيها الحلو والوحش \n",
              "61118      انا بقيت ب  اعمل كده على فكرة   و ليه اوجع اي...\n",
              "48452     البوست بتاع خافيير سولانا طلع انه فيه هاكر ترك...\n",
              "95030                   احلي    دي ولا ايه  افريقيا يا وداد\n",
              "96136                             حبيبى قدها يا كبير والله \n",
              "1966       بيجنننن وحبيت كتير كتير  البرمووو الف مبرووك ...\n",
              "73177     فيه سمكه إسمها رعيده بترعدبتكهرب يعني حجمها صغ...\n",
              "73035     بالنسبه للنجوم اللي بيدافعو عن المقشفه  وبيقول...\n",
              "92410     اللى هيتابعنى هتابعه كلام معلمين الخميس الامير...\n",
              "121942     مشلفه هيدي  اذا صبيه تستعمل هيك منطق وهيك الف...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def remove_underscores_and_enter(text):\n",
        "    pattern = r'[_\\n]'\n",
        "    text = re.sub(pattern, ' ', text)\n",
        "    return text\n",
        "\n",
        "X_train = X_train.apply(remove_underscores_and_enter)\n",
        "\n",
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cLxToGwNWjl",
        "outputId": "0085a00b-4a0c-4653-c23f-6b421e827e82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57485                           الدنيا دي فيها الحلو والوحش\n",
              "61118     انا بقيت ب اعمل كده على فكرة و ليه اوجع ايدي ت...\n",
              "48452     البوست بتاع خافيير سولانا طلع انه فيه هاكر ترك...\n",
              "95030                       احلي دي ولا ايه افريقيا يا وداد\n",
              "96136                              حبيبى قدها يا كبير والله\n",
              "1966      بيجنننن وحبيت كتير كتير البرمووو الف مبرووك حب...\n",
              "73177     فيه سمكه إسمها رعيده بترعدبتكهرب يعني حجمها صغ...\n",
              "73035     بالنسبه للنجوم اللي بيدافعو عن المقشفه وبيقولو...\n",
              "92410     اللى هيتابعنى هتابعه كلام معلمين الخميس الامير...\n",
              "121942    مشلفه هيدي اذا صبيه تستعمل هيك منطق وهيك الفاظ...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def remove_extra_spaces(text):\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "X_train = X_train.apply(remove_extra_spaces)\n",
        "\n",
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goP44AZ4NWjl"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = remove_english_characters(text)\n",
        "    text = remove_numbers(text)\n",
        "    text = remove_special_characters(text)\n",
        "    text = remove_underscores_and_enter(text)\n",
        "    text = remove_extra_spaces(text)\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rn4-CZQCNWjl",
        "outputId": "023d4710-91fd-4dbe-f8e5-a2dd4e641412"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8295819935691319"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "X_test = X_test.apply(clean_text)\n",
        "\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgrpKRmhNWjl",
        "outputId": "12604510-5b50-4632-adec-f74580f219fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['EG'], dtype=object)"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_text = ' ليه اوجع ايدي'\n",
        "cleaned_text = clean_text(new_text)\n",
        "\n",
        "new_text_vectorized = vectorizer.transform([cleaned_text])\n",
        "\n",
        "model.predict(new_text_vectorized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmPbPz2GNWjm",
        "outputId": "7ddeb66f-1112-41af-b53b-60309b9be27f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8329666610255543"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "\n",
        "accuracy_score(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBqN-Cu0NWjm",
        "outputId": "aa046774-5f0a-4b60-9bec-30a59eee0fcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['EG'], dtype='<U2')"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_text = ' ليه اوجع ايدي'\n",
        "cleaned_text = clean_text(new_text)\n",
        "\n",
        "new_text_vectorized = vectorizer.transform([cleaned_text])\n",
        "\n",
        "model.predict(new_text_vectorized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qMJlLTONWjm",
        "outputId": "c257976a-bb11-4ca6-af24-9499afd1eda9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2955/2955 [==============================] - 818s 274ms/step - loss: 1.4565 - accuracy: 0.3913 - val_loss: 1.4524 - val_accuracy: 0.3869\n",
            "Epoch 2/10\n",
            "2955/2955 [==============================] - 806s 273ms/step - loss: 1.4539 - accuracy: 0.3914 - val_loss: 1.4531 - val_accuracy: 0.3869\n",
            "Epoch 3/10\n",
            "2955/2955 [==============================] - 835s 283ms/step - loss: 1.4533 - accuracy: 0.3914 - val_loss: 1.4521 - val_accuracy: 0.3869\n",
            "Epoch 4/10\n",
            "2955/2955 [==============================] - 836s 283ms/step - loss: 1.4532 - accuracy: 0.3914 - val_loss: 1.4522 - val_accuracy: 0.3869\n",
            "Epoch 5/10\n",
            "2955/2955 [==============================] - 820s 277ms/step - loss: 1.4531 - accuracy: 0.3914 - val_loss: 1.4523 - val_accuracy: 0.3869\n",
            "Epoch 6/10\n",
            "2955/2955 [==============================] - 809s 274ms/step - loss: 1.4530 - accuracy: 0.3914 - val_loss: 1.4523 - val_accuracy: 0.3869\n",
            "924/924 [==============================] - 58s 60ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#make a deep learning model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_sequences, padding='post', maxlen=100)\n",
        "\n",
        "X_test_padded = pad_sequences(X_test_sequences, padding='post', maxlen=100)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=100))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "model.fit(X_train_padded, y_train_categorical, validation_split=0.2, epochs=10, callbacks=[early_stopping])\n",
        "\n",
        "y_pred = model.predict(X_test_padded)\n",
        "\n",
        "y_pred = y_pred.argmax(axis=1)\n",
        "\n",
        "accuracy_score(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHotwhKkNWjm",
        "outputId": "923ff740-6b50-42c2-c0e1-e0cd8ae2ec2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ahmed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "#save the model\n",
        "model.save('dialects_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gd40hIvNWjm",
        "outputId": "5181bbbb-f0b3-4bb4-d44a-6aedac05efd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 928 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002651D138A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array(['SD'], dtype=object)"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#try the model\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('dialects_model.h5')\n",
        "\n",
        "new_text = 'يد'\n",
        "cleaned_text = clean_text(new_text)\n",
        "\n",
        "new_text_sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
        "\n",
        "new_text_padded = pad_sequences(new_text_sequence, padding='post', maxlen=100)\n",
        "\n",
        "model.predict(new_text_padded)\n",
        "\n",
        "label_encoder.inverse_transform([4])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu-fM1xSNWjm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
