{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee79890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:28:04.406569Z",
     "iopub.status.busy": "2024-06-13T09:28:04.406242Z",
     "iopub.status.idle": "2024-06-13T09:28:20.546788Z",
     "shell.execute_reply": "2024-06-13T09:28:20.545578Z"
    },
    "id": "--g4T0CPOhIS",
    "outputId": "1ff54361-f7b4-4ba3-df1a-f685a52e9114",
    "papermill": {
     "duration": 16.149435,
     "end_time": "2024-06-13T09:28:20.549037",
     "exception": false,
     "start_time": "2024-06-13T09:28:04.399602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (1.4.2)\r\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.3.3)\r\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\r\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.0)\r\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.8)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.10.0)\r\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras) (0.11.0)\r\n",
      "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.2.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.59.3)\r\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\r\n",
      "Collecting keras\r\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\r\n",
      "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: keras\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.3.3\r\n",
      "    Uninstalling keras-3.3.3:\r\n",
      "      Successfully uninstalled keras-3.3.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed keras-2.15.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn joblib keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c54250a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:28:20.564478Z",
     "iopub.status.busy": "2024-06-13T09:28:20.564184Z",
     "iopub.status.idle": "2024-06-13T09:28:20.568145Z",
     "shell.execute_reply": "2024-06-13T09:28:20.567308Z"
    },
    "id": "Uhm0UxbiWN7R",
    "outputId": "6da0e3f5-1850-40b2-dc20-1ba68eade5ff",
    "papermill": {
     "duration": 0.013866,
     "end_time": "2024-06-13T09:28:20.569948",
     "exception": false,
     "start_time": "2024-06-13T09:28:20.556082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# main_dir = '/content/drive/MyDrive/NLP/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d7453f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:28:20.584429Z",
     "iopub.status.busy": "2024-06-13T09:28:20.584182Z",
     "iopub.status.idle": "2024-06-13T09:28:33.845701Z",
     "shell.execute_reply": "2024-06-13T09:28:33.844914Z"
    },
    "id": "zr7-nCL_OghC",
    "papermill": {
     "duration": 13.271398,
     "end_time": "2024-06-13T09:28:33.848059",
     "exception": false,
     "start_time": "2024-06-13T09:28:20.576661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 09:28:24.342516: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-13 09:28:24.342622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-13 09:28:24.472983: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d64dac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:28:33.863700Z",
     "iopub.status.busy": "2024-06-13T09:28:33.863197Z",
     "iopub.status.idle": "2024-06-13T09:28:33.868827Z",
     "shell.execute_reply": "2024-06-13T09:28:33.867983Z"
    },
    "id": "jg6epQS9OkBQ",
    "papermill": {
     "duration": 0.015502,
     "end_time": "2024-06-13T09:28:33.870781",
     "exception": false,
     "start_time": "2024-06-13T09:28:33.855279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Database loading\n",
    "class DataLoader:\n",
    "    def __init__(self, dbfile):\n",
    "        self.dbfile = dbfile\n",
    "\n",
    "    def load_data(self):\n",
    "        conn = sqlite3.connect(self.dbfile)\n",
    "        data_df = pd.read_sql(\"SELECT * FROM id_text\", conn)\n",
    "        type_df = pd.read_sql(\"SELECT * FROM id_dialect\", conn)\n",
    "        conn.close()\n",
    "        return data_df, type_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5137a4db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:28:33.885619Z",
     "iopub.status.busy": "2024-06-13T09:28:33.885363Z",
     "iopub.status.idle": "2024-06-13T09:28:33.897358Z",
     "shell.execute_reply": "2024-06-13T09:28:33.896482Z"
    },
    "id": "O9KqpQiPOniV",
    "papermill": {
     "duration": 0.021689,
     "end_time": "2024-06-13T09:28:33.899299",
     "exception": false,
     "start_time": "2024-06-13T09:28:33.877610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.Series(X)\n",
    "        return X.apply(self.clean_text)\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        text = TextCleaner.remove_urls(text)\n",
    "        text = TextCleaner.remove_mentions(text)\n",
    "        text = TextCleaner.remove_english_words(text)\n",
    "        text = TextCleaner.remove_unicode_bmp(text)\n",
    "        text = TextCleaner.remove_emoji_shortcodes(text)\n",
    "        text = TextCleaner.remove_specific_punctuation(text)\n",
    "        text = TextCleaner.remove_complex_patterns(text)\n",
    "        text = TextCleaner.remove_various_punctuation(text)\n",
    "        text = TextCleaner.remove_numbers(text)\n",
    "        text = TextCleaner.remove_extra_spaces(text)\n",
    "        return text\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_urls(text):\n",
    "        return re.sub(r'http[s]?://\\S+', ' ', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_mentions(text):\n",
    "        return re.sub(r'@\\w+', ' ', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_english_words(text):\n",
    "        return re.sub(r'\\b[a-zA-Z]+\\b', ' ', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_unicode_bmp(text):\n",
    "        return re.sub(r'[\\U00010000-\\U0010ffff]', ' ', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_emoji_shortcodes(text):\n",
    "        return re.sub(r':[a-z_]+:', ' ', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_specific_punctuation(text):\n",
    "        return re.sub(r'[*!?#@]', ' ', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_complex_patterns(text):\n",
    "        return re.sub(r'\\|\\|+\\\\s*\\d+%\\s*\\|\\|+?[_\\-\\.\\?]+', ' ', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_various_punctuation(text):\n",
    "        return re.sub(r'[_\\-\\.\\\"\\:\\;\\,\\'\\،\\♡\\\\\\)/(\\&\\؟]', ' ', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_numbers(text):\n",
    "        return re.sub(r'\\d+', ' ', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_extra_spaces(text):\n",
    "        return ' '.join(text.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc7afc7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:28:33.914136Z",
     "iopub.status.busy": "2024-06-13T09:28:33.913880Z",
     "iopub.status.idle": "2024-06-13T09:28:33.922196Z",
     "shell.execute_reply": "2024-06-13T09:28:33.921396Z"
    },
    "id": "B7JQPq7vOql8",
    "papermill": {
     "duration": 0.017916,
     "end_time": "2024-06-13T09:28:33.924029",
     "exception": false,
     "start_time": "2024-06-13T09:28:33.906113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Training\n",
    "class TextClassificationModel:\n",
    "    def __init__(self, model_type='logistic'):\n",
    "        self.model_type = model_type\n",
    "        self.pipeline = None\n",
    "\n",
    "    def build_pipeline(self):\n",
    "        if self.model_type == 'logistic':\n",
    "            self.pipeline = Pipeline([\n",
    "                ('cleaner', TextCleaner()),\n",
    "                ('vectorizer', CountVectorizer()),\n",
    "                ('classifier', LogisticRegression())\n",
    "            ])\n",
    "        elif self.model_type == 'naive_bayes':\n",
    "            self.pipeline = Pipeline([\n",
    "                ('cleaner', TextCleaner()),\n",
    "                ('vectorizer', CountVectorizer()),\n",
    "                ('classifier', MultinomialNB())\n",
    "            ])\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.build_pipeline()\n",
    "        self.pipeline.fit(X_train, y_train)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.pipeline.predict(X_test)\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "\n",
    "    def save(self, filename):\n",
    "        joblib.dump(self.pipeline, filename)\n",
    "\n",
    "    def load(self, filename):\n",
    "        self.pipeline = joblib.load(filename)\n",
    "\n",
    "    def predict(self, text):\n",
    "        return self.pipeline.predict([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46962d9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:28:33.938859Z",
     "iopub.status.busy": "2024-06-13T09:28:33.938585Z",
     "iopub.status.idle": "2024-06-13T09:28:33.953300Z",
     "shell.execute_reply": "2024-06-13T09:28:33.952602Z"
    },
    "id": "1KwoFZB9OudI",
    "papermill": {
     "duration": 0.024048,
     "end_time": "2024-06-13T09:28:33.955007",
     "exception": false,
     "start_time": "2024-06-13T09:28:33.930959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deep Learning Model\n",
    "class DeepLearningModel:\n",
    "    def __init__(self, max_len=100):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self, input_dim, output_dim):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Embedding(input_dim=input_dim, output_dim=100, input_length=self.max_len))\n",
    "        self.model.add(LSTM(100, return_sequences=True))\n",
    "        self.model.add(LSTM(100))\n",
    "        self.model.add(Dense(100, activation='relu'))\n",
    "        self.model.add(Dropout(0.2))\n",
    "        self.model.add(Dense(output_dim, activation='softmax'))\n",
    "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def preprocess_text(self, texts):\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        return pad_sequences(sequences, padding='post', maxlen=self.max_len)\n",
    "\n",
    "    def train(self, X_train, y_train, validation_split=0.2, epochs=10, patience=3):\n",
    "        self.tokenizer.fit_on_texts(X_train)\n",
    "        X_train_padded = self.preprocess_text(X_train)\n",
    "        y_train_encoded = self.label_encoder.fit_transform(y_train)\n",
    "        y_train_categorical = to_categorical(y_train_encoded)\n",
    "        self.build_model(len(self.tokenizer.word_index)+1, len(self.label_encoder.classes_))\n",
    "        early_stopping = EarlyStopping(patience=patience)\n",
    "        self.model.fit(X_train_padded, y_train_categorical, validation_split=validation_split, epochs=epochs, callbacks=[early_stopping])\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        X_test_padded = self.preprocess_text(X_test)\n",
    "        y_test_encoded = self.label_encoder.transform(y_test)\n",
    "        y_pred = self.model.predict(X_test_padded)\n",
    "        y_pred_classes = y_pred.argmax(axis=1)\n",
    "        return accuracy_score(y_test_encoded, y_pred_classes)\n",
    "\n",
    "    def save(self, model_filename, tokenizer_filename, label_encoder_filename):\n",
    "        self.model.save(model_filename)\n",
    "        joblib.dump(self.tokenizer, tokenizer_filename)\n",
    "        joblib.dump(self.label_encoder, label_encoder_filename)\n",
    "\n",
    "    def load(self, model_filename, tokenizer_filename, label_encoder_filename):\n",
    "        self.model = load_model(model_filename)\n",
    "        self.tokenizer = joblib.load(tokenizer_filename)\n",
    "        self.label_encoder = joblib.load(label_encoder_filename)\n",
    "\n",
    "    def predict(self, text):\n",
    "        cleaned_text = TextCleaner.clean_text(text)\n",
    "        sequence = self.tokenizer.texts_to_sequences([cleaned_text])\n",
    "        padded_sequence = pad_sequences(sequence, padding='post', maxlen=self.max_len)\n",
    "        prediction = self.model.predict(padded_sequence)\n",
    "        return self.label_encoder.inverse_transform(prediction.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b63c1ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:28:33.969671Z",
     "iopub.status.busy": "2024-06-13T09:28:33.969412Z",
     "iopub.status.idle": "2024-06-13T09:28:33.973008Z",
     "shell.execute_reply": "2024-06-13T09:28:33.972272Z"
    },
    "papermill": {
     "duration": 0.012953,
     "end_time": "2024-06-13T09:28:33.974739",
     "exception": false,
     "start_time": "2024-06-13T09:28:33.961786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_dir = '/kaggle/input/arabic-dialect-db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f421c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:28:33.989150Z",
     "iopub.status.busy": "2024-06-13T09:28:33.988893Z",
     "iopub.status.idle": "2024-06-13T09:28:34.940140Z",
     "shell.execute_reply": "2024-06-13T09:28:34.939340Z"
    },
    "id": "xVZAJDaeOz_W",
    "papermill": {
     "duration": 0.961015,
     "end_time": "2024-06-13T09:28:34.942456",
     "exception": false,
     "start_time": "2024-06-13T09:28:33.981441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dbfile = f'{main_dir}/dialects_database.db'\n",
    "data_loader = DataLoader(dbfile)\n",
    "data_df, type_df = data_loader.load_data()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_df['text'], type_df['dialect'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce86a952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:28:34.958330Z",
     "iopub.status.busy": "2024-06-13T09:28:34.957614Z",
     "iopub.status.idle": "2024-06-13T09:29:22.879223Z",
     "shell.execute_reply": "2024-06-13T09:29:22.878157Z"
    },
    "id": "Y_MaK1DbO4bQ",
    "outputId": "3a04fa95-0baa-41b7-d2ec-56b00d9349bc",
    "papermill": {
     "duration": 47.931837,
     "end_time": "2024-06-13T09:29:22.881700",
     "exception": false,
     "start_time": "2024-06-13T09:28:34.949863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8313081739719073\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "logistic_model = TextClassificationModel(model_type='logistic')\n",
    "logistic_model.train(X_train, y_train)\n",
    "print(\"Logistic Regression Accuracy:\", logistic_model.evaluate(X_test, y_test))\n",
    "logistic_model.save('logistic_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3ec3c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:29:22.897523Z",
     "iopub.status.busy": "2024-06-13T09:29:22.897186Z",
     "iopub.status.idle": "2024-06-13T09:29:34.262404Z",
     "shell.execute_reply": "2024-06-13T09:29:34.261588Z"
    },
    "id": "yIgiqqArO68G",
    "outputId": "85ef6319-d7c2-48b4-ab37-bc430d425759",
    "papermill": {
     "duration": 11.375629,
     "end_time": "2024-06-13T09:29:34.264661",
     "exception": false,
     "start_time": "2024-06-13T09:29:22.889032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.8337112878659672\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Model\n",
    "nb_model = TextClassificationModel(model_type='naive_bayes')\n",
    "nb_model.train(X_train, y_train)\n",
    "print(\"Naive Bayes Accuracy:\", nb_model.evaluate(X_test, y_test))\n",
    "nb_model.save('nb_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4273b854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:29:34.282151Z",
     "iopub.status.busy": "2024-06-13T09:29:34.281432Z",
     "iopub.status.idle": "2024-06-13T09:36:50.279876Z",
     "shell.execute_reply": "2024-06-13T09:36:50.278590Z"
    },
    "id": "b8xCRxeyO8Bn",
    "outputId": "b2d89d3f-3364-45e2-d7f9-eb58b8418e5f",
    "papermill": {
     "duration": 436.009534,
     "end_time": "2024-06-13T09:36:50.282286",
     "exception": false,
     "start_time": "2024-06-13T09:29:34.272752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718270989.116724      76 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2955/2955 [==============================] - 96s 31ms/step - loss: 1.4565 - accuracy: 0.3914 - val_loss: 1.4521 - val_accuracy: 0.3869\n",
      "Epoch 2/10\n",
      "2955/2955 [==============================] - 54s 18ms/step - loss: 1.4540 - accuracy: 0.3914 - val_loss: 1.4526 - val_accuracy: 0.3869\n",
      "Epoch 3/10\n",
      "2955/2955 [==============================] - 52s 18ms/step - loss: 1.4535 - accuracy: 0.3914 - val_loss: 1.4524 - val_accuracy: 0.3869\n",
      "Epoch 4/10\n",
      "2955/2955 [==============================] - 52s 17ms/step - loss: 1.4531 - accuracy: 0.3914 - val_loss: 1.4520 - val_accuracy: 0.3869\n",
      "Epoch 5/10\n",
      "2955/2955 [==============================] - 50s 17ms/step - loss: 1.4531 - accuracy: 0.3914 - val_loss: 1.4527 - val_accuracy: 0.3869\n",
      "Epoch 6/10\n",
      "2955/2955 [==============================] - 51s 17ms/step - loss: 1.4530 - accuracy: 0.3914 - val_loss: 1.4521 - val_accuracy: 0.3869\n",
      "Epoch 7/10\n",
      "2955/2955 [==============================] - 51s 17ms/step - loss: 1.4530 - accuracy: 0.3914 - val_loss: 1.4527 - val_accuracy: 0.3869\n",
      "924/924 [==============================] - 6s 5ms/step\n",
      "Deep Learning Model Accuracy: 0.3886952106955492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Deep Learning Model\n",
    "dl_model = DeepLearningModel(max_len=100)\n",
    "dl_model.train(X_train, y_train, epochs=10, patience=3)\n",
    "print(\"Deep Learning Model Accuracy:\", dl_model.evaluate(X_test, y_test))\n",
    "dl_model.save('dl_model.h5', 'tokenizer.pkl', 'label_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb95f928",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:36:51.216493Z",
     "iopub.status.busy": "2024-06-13T09:36:51.216133Z",
     "iopub.status.idle": "2024-06-13T09:36:51.220861Z",
     "shell.execute_reply": "2024-06-13T09:36:51.219893Z"
    },
    "papermill": {
     "duration": 0.447344,
     "end_time": "2024-06-13T09:36:51.222869",
     "exception": false,
     "start_time": "2024-06-13T09:36:50.775525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7dc5e44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:36:52.103733Z",
     "iopub.status.busy": "2024-06-13T09:36:52.103357Z",
     "iopub.status.idle": "2024-06-13T09:37:03.692726Z",
     "shell.execute_reply": "2024-06-13T09:37:03.691539Z"
    },
    "id": "CKUcJhwTOZCn",
    "papermill": {
     "duration": 12.032607,
     "end_time": "2024-06-13T09:37:03.694938",
     "exception": false,
     "start_time": "2024-06-13T09:36:51.662331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Prediction: ['EG']\n",
      "Naive Bayes Prediction: ['EG']\n",
      "1/1 [==============================] - 1s 657ms/step\n",
      "Deep Learning Model Prediction: ['EG']\n"
     ]
    }
   ],
   "source": [
    "# Inference Example\n",
    "new_text ='ليه اوجع ايدي'\n",
    "\n",
    "# Logistic Regression Inference\n",
    "logistic_model.load('logistic_model.pkl')\n",
    "print(\"Logistic Regression Prediction:\", logistic_model.predict(new_text))\n",
    "\n",
    "# Naive Bayes Inference\n",
    "nb_model.load('nb_model.pkl')\n",
    "print(\"Naive Bayes Prediction:\", nb_model.predict(new_text))\n",
    "\n",
    "# Deep Learning Model Inference\n",
    "dl_model.load('dl_model.h5', 'tokenizer.pkl', 'label_encoder.pkl')\n",
    "print(\"Deep Learning Model Prediction:\", dl_model.predict(new_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddcb7aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T09:37:04.621830Z",
     "iopub.status.busy": "2024-06-13T09:37:04.621450Z",
     "iopub.status.idle": "2024-06-13T09:37:16.133259Z",
     "shell.execute_reply": "2024-06-13T09:37:16.132299Z"
    },
    "papermill": {
     "duration": 11.998226,
     "end_time": "2024-06-13T09:37:16.135326",
     "exception": false,
     "start_time": "2024-06-13T09:37:04.137100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Prediction: ['LY']\n",
      "Naive Bayes Prediction: ['LY']\n",
      "1/1 [==============================] - 1s 656ms/step\n",
      "Deep Learning Model Prediction: ['EG']\n"
     ]
    }
   ],
   "source": [
    "# Inference Example\n",
    "new_text ='في ناس مليح اللي ما في متلن'\n",
    "\n",
    "# Logistic Regression Inference\n",
    "logistic_model.load('logistic_model.pkl')\n",
    "print(\"Logistic Regression Prediction:\", logistic_model.predict(new_text))\n",
    "\n",
    "# Naive Bayes Inference\n",
    "nb_model.load('nb_model.pkl')\n",
    "print(\"Naive Bayes Prediction:\", nb_model.predict(new_text))\n",
    "\n",
    "# Deep Learning Model Inference\n",
    "dl_model.load('dl_model.h5', 'tokenizer.pkl', 'label_encoder.pkl')\n",
    "print(\"Deep Learning Model Prediction:\", dl_model.predict(new_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea31d1c0",
   "metadata": {
    "papermill": {
     "duration": 0.433605,
     "end_time": "2024-06-13T09:37:17.008548",
     "exception": false,
     "start_time": "2024-06-13T09:37:16.574943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5200425,
     "sourceId": 8676006,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 558.50784,
   "end_time": "2024-06-13T09:37:20.036823",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-13T09:28:01.528983",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
